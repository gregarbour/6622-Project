---
title: "GLM Data Analysis Final Project"
author: "Greg Arbour & Konstantinos Ntentes"
date: "Winter 2020"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Objective

Find a dataset with a non-continuous response variable and at least seven explanatory variables (at least two of them categorical). Use the techniques learned in the Generalized Linear Models course (MATH 6622) to analyze the data and report the statistical results.

The data are obtained from the US National Medical Expenditure Survey (NMES) which was conducted in 1987 and 1988 to provide a comprehensive picture of how Americans use and pay for health services. We consider a subsample of individuals ages 66 and over all of whom are covered by Medicare, a public insurance programme that offers substantial protection against health care costs in the United States. This data is taken from the paper **Demand for Medical Care by the Eldery: A Finite Mixture Approach** by Partha Deb and Pravin K. Trivedi.

##### Model Response

We are looking to model the **number of non-hospital physician office visits over the course of a year** for the observed seniors, predicted both in terms of personal characteristic variables like age, minority status and income, as well as some other macro-variables like the region of the United States in which each senior resides. 

In this project, we will be working from a predictive standpoint and will try to attain the leanest possible model to model the number of physician visits, and will not attempt to model the causal effect relationship between the predictors and the response. 

### Data Directory

The dataset provided includes 4406 observations and 22 variables including our response. All the observations will be used, but only a subset of the predictors will be included in our analysis.

The variables correspond to measurements of counts and personal characterstics in the year 1987, and can be described as follows:


**`ofp`**: number of physician office visits in the measured year (our response count variable)

**`health`**: categorical variable measuring self-perceived health level (can take values `poor`, `average` or `excellent`)

**`numchron`**: number of chronic health conditions the person surveyed has (including cancer, previous heart attack, gall bladder problems, emphysema, arthritis, diabetes, or other heart diseases)

**`adldiff`**: categorical variable measuring whether or not the person has a condition that limits the activities of daily living (can take values `no` or `yes`)

**`region`**: categorical variable that states the geographical region of the United States in which the person lives (can take values `noreast`, `midwest`, `west` or `other`)

**`age`**: $(\text{age in years})\times 10^{-1}$ of the person

**`black`**: categorical variable stating whether or not the person is of African American heritage (can take values `no` or `yes`)

**`gender`**: categorical variable stating whether the person is male or female (can take values `male` or `female`)

**`married`**: categorical variable stating whether or not the person is married (can take values `no` or `yes`)

**`school`**: number of years of education of the person

**`faminc`**: $(\text{yearly income}) \times \$ 10,000^{-1}$ of the household of the person

**`employed`**: categorical variable stating whether or not the person is employed (can take values `no` or `yes`)

**`privins`**: categorical variable stating whether or not the person is covered by private health insurance (can take values `no` or `yes`)

**`medicaid`**: categorical variable stating whether or not the person is covered by Medicaid (can take values `no` or `yes`)

This still leaves us with all 4406 observations but reduces the number of variables to 14.

### Exploratory Data Analysis

##### Data Cleaning

First, we load in the data and take a look at the first few observations (note that the following table is interactive and scrollable):

```{r, echo=FALSE}
set.seed(1337)

load('DebTrivedi')
df <- DebTrivedi[ , c(1, 7:19)]
remove(DebTrivedi)

## Interactive Table (Scroll right and left)
head(df)
```

All of the variables seem to be in a workable state - although some data cleaning can idealize the dataset. We will change all of the two-factor categorical variables, including `adldiff`, `black`, `gender`, `married`, `employed`, `privins`, and `medicaid` into logical variables.

**Note**: the variable name for `gender` was changed to `male` when it was translated into a logical variable for easy interpretation.

Let's take a look at the state of missingness in the data set:

```{r, echo=FALSE}
library(visdat)

if (!is.logical(df$adldiff)){
## adldiff
df$adldiff <- as.logical(as.numeric(df$adldiff) - 1)

## black
df$black <- as.logical(as.numeric(df$black) - 1)

## gender (true = male, name change to male instead of gender)
df$gender <- as.logical(as.numeric(df$gender) - 1)

## married
df$married <- as.logical(as.numeric(df$married) - 1)

## employed 
df$employed <- as.logical(as.numeric(df$employed) - 1)

## privins 
df$privins <- as.logical(as.numeric(df$privins) - 1)

## medicaid 
df$medicaid <- as.logical(as.numeric(df$medicaid) - 1)

# change name of gender to male
varnames <- names(df)
varnames[8] <- 'male'
names(df) <- varnames
}

print("How many NA's are in each column?")
t(data.frame("NA.Freq" = colSums(is.na(df))))
```

It looks like we don't have any missing values, which is rare for medical data, but it is great for our analysis nonetheless.

##### Generalized Linear Model

When dealing with count data as a response variable, it is natural to first approach modelling the data using Poisson regression and the log-link function.

Identifying if the response variable is rate data or not is another important aspect in order to determine whether an offset is required in your model. In our case, as per the data description, all measurements were taken over the course of the year 1987, hence the counts are all over the same length of time and we do not require an offset in our model as our data is not rate data.

We will attempt to fit the saturated model to take a preliminary look:

```{r}
var <- c('health', 'adldiff', 'region', 'age', 'male', 'black', 
          'married', 'school', 'faminc', 'employed', 'privins', 'medicaid')
form <- as.formula(paste('ofp ~', paste(var, collapse = ' + ')))
pfit <- glm(form, data = df, family = poisson(link = 'log'))
summary(pfit)
```

We can see that quite a few variables show strong statistical association with the response, but we should take a look at how the response variable `ofp` looks when compared to a vector of Poisson randomly generated values with the same means:

```{r, echo=FALSE}
## Output fitted values to use distribution plot
pfitted <- fitted(pfit)

dataplot2 <- function(x, lambda = lambda){
  poigen <- rpois(length(x), lambda = lambda)
  barplot(table(x), xlab = "Number of Physician Office Visits in 1987", ylim = c(0, 800),
          ylab = "Response Frequency", xlim = c(0, ifelse(length(unique(poigen))>=length(unique(x)), 
                                                 length(unique(poigen))+2, min(length(unique(x))+2, 24.9))),
          main = "Distribution Comparison of Response")
  if (length(unique(x))>=length(unique(poigen))){
    barplot(table(poigen), width=0.5, space=c(0.9, rep(1.4, length(unique(poigen))-1)), 
            col="red", add=TRUE, names.arg = "")
  } else {
    barplot(table(poigen), width=0.5, space=c(0.9, rep(1.4, length(unique(poigen))-1)), 
            col="red", add=TRUE, names.arg = c(rep("", length(unique(x))), (length(unique(x)) + 1):length(unique(poigen))))
  }
  legend(15, max(max(table(x)), max(table(poigen))) - 150, 
         legend=c("Data", expression(paste("Poisson Dist., ", lambda, " = ", mu[i]))),
         col=c("grey", "red"), pch= 15, cex = 0.8)
}

dataplot2(df$ofp, lambda = pfitted)
```

It's quite clear that `ofp` doesn't follow a regular Poisson distribution, and some peculiar characteristics of the response variable's distribution are evident in the plot. For the sake of convenience we let the random variable $X$ represent the `ofp` response. We note that the mean of `ofp` is $\lambda = E[X] = `r mean(df$ofp)`, but the variance of the distribution is much higher than the mean, with $\text{Var}(X) = `r var(df$ofp)` \ne \lambda$. This is called overdispersion, and we can see this visually in the plot by looking at the spread of the grey data, and how much further left and right of the red true distribution it spreads.

We can fit the response variable to 



