---
title: "GLM Data Analysis Final Project"
author: "Greg Arbour & Konstantinos Ntentes"
date: "Winter 2020"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(AER)
library(MASS)
library(broom)
library(pscl)
```

### Objective

Find a dataset with a non-continuous response variable and at least seven explanatory variables (at least two of them categorical). Use the techniques learned in the Generalized Linear Models course (MATH 6622) to analyze the data and report the statistical results.

The data are obtained from the US National Medical Expenditure Survey (NMES) which was conducted in 1987 and 1988 to provide a comprehensive picture of how Americans use and pay for health services. We consider a subsample of individuals ages 66 and over all of whom are covered by Medicare, a public insurance programme that offers substantial protection against health care costs in the United States. This data is taken from the paper **Demand for Medical Care by the Eldery: A Finite Mixture Approach** by Partha Deb and Pravin K. Trivedi.

##### Model Response

We attempt to model the **number of non-hospital physician office visits over the course of a year** for the observed seniors, predicted both in terms of personal characteristic variables like age, minority status and income, as well as some other macro-variables like the region of the United States in which each senior resides. 

In this project, we will be working from a predictive standpoint and will try to attain the leanest possible model to model the number of physician visits, and will not attempt to model the causal effect relationship between the predictors and the response. 

### Data Directory

The dataset provided includes 4406 observations and 22 variables including our response. All the observations will be used, but only a subset of the predictors will be included in our analysis.

The variables correspond to measurements of counts and personal characterstics in the year 1987, and can be described as follows:


**`ofp`**: number of physician office visits in the measured year **(our response count variable)**

**`health`**: categorical variable measuring self-perceived health level (can take values `poor`, `average` or `excellent`)

**`numchron`**: number of chronic health conditions the person surveyed has (including cancer, previous heart attack, gall bladder problems, emphysema, arthritis, diabetes, or other heart diseases)

**`adldiff`**: categorical variable measuring whether or not the person has a condition that limits the activities of daily living (can take values `no` or `yes`)

**`region`**: categorical variable that states the geographical region of the United States in which the person lives (can take values `noreast`, `midwest`, `west` or `other`)

**`age`**: $(\text{age in years})\times 10^{-1}$ of the person

**`black`**: categorical variable stating whether or not the person is of African American heritage (can take values `no` or `yes`)

**`gender`**: categorical variable stating whether the person is male or female (can take values `male` or `female`)

**`married`**: categorical variable stating whether or not the person is married (can take values `no` or `yes`)

**`school`**: number of years of education of the person

**`faminc`**: $(\text{yearly income}) \times \$ 10,000^{-1}$ of the household of the person

**`employed`**: categorical variable stating whether or not the person is employed (can take values `no` or `yes`)

**`privins`**: categorical variable stating whether or not the person is covered by private health insurance (can take values `no` or `yes`)

**`medicaid`**: categorical variable stating whether or not the person is covered by Medicaid (can take values `no` or `yes`)

This still leaves us with all 4406 observations but reduces the number of variables to 14.

```{r include = T, echo = F}
sum_table <- read.csv('Summary Table Final.csv')
kable(sum_table)
```

### Exploratory Data Analysis

##### Data Cleaning

First, we load in the data and take a look at the first few observations (note that the following table is interactive and scrollable):

```{r, echo=FALSE}
set.seed(1337)

load('DebTrivedi')
df <- DebTrivedi[ , c(1, 7:19)]
remove(DebTrivedi)

## Interactive Table (Scroll right and left)
head(df)
```

All of the variables seem to be in a workable state - although some data cleaning can idealize the dataset. We will change all of the two-factor categorical variables, including `adldiff`, `black`, `gender`, `married`, `employed`, `privins`, and `medicaid` into logical variables.

**Note**: the variable name for `gender` was changed to `male` when it was translated into a logical variable for easy interpretation.

Let's take a look at the state of missingness in the data set:

```{r, echo=FALSE}
library(visdat)

if (!is.logical(df$adldiff)){
## adldiff
df$adldiff <- as.logical(as.numeric(df$adldiff) - 1)

## black
df$black <- as.logical(as.numeric(df$black) - 1)

## gender (true = male, name change to male instead of gender)
df$gender <- as.logical(as.numeric(df$gender) - 1)

## married
df$married <- as.logical(as.numeric(df$married) - 1)

## employed 
df$employed <- as.logical(as.numeric(df$employed) - 1)

## privins 
df$privins <- as.logical(as.numeric(df$privins) - 1)

## medicaid 
df$medicaid <- as.logical(as.numeric(df$medicaid) - 1)

# change name of gender to male
varnames <- names(df)
varnames[8] <- 'male'
names(df) <- varnames
}

print("How many NA's are in each column?")
t(data.frame("NA.Freq" = colSums(is.na(df))))
```

It looks like we don't have any missing values, which is rare for medical data, but it is great for our analysis nonetheless.

##### Baseline Generalized Linear Model

When dealing with count data as a response variable, it is natural to first approach modelling the data using Poisson regression and the log-link function.

Identifying if the response variable is rate data or not is another important aspect in order to determine whether an offset is required in your model. In our case, as per the data description, all measurements were taken over the course of the year 1987, hence the counts are all over the same length of time and we do not require an offset in our model as our data is not rate data.

We will attempt to fit the full model to take a preliminary look:

```{r}
var <- c('health', 'adldiff', 'region', 'age', 'male', 'black', 
          'married', 'school', 'faminc', 'employed', 'privins', 'medicaid')
form <- as.formula(paste('ofp ~', paste(var, collapse = ' + ')))
pfit <- glm(form, data = df, family = poisson(link = 'log'))
broom::tidy(pfit)
```

We can see that quite a few variables show strong statistical association with the response, but we should take a look at how the response variable `ofp` looks when compared to a vector of Poisson randomly generated values with the same means:

```{r}
## Output fitted values to use distribution plot
pfitted <- fitted(pfit)
```

```{r, echo=FALSE}
mui <- mean(df$ofp)
vari <- var(df$ofp)

dataplot2 <- function(x, lambda = lambda){
  poigen <- rpois(length(x), lambda = lambda)
  barplot(table(x), xlab = "Number of Physician Office Visits in 1987", ylim = c(0, 800),
          ylab = "Response Frequency", xlim = c(0, ifelse(length(unique(poigen))>=length(unique(x)), 
                                                 length(unique(poigen))+2, min(length(unique(x))+2, 24.9))),
          main = "Distribution Comparison of Response")
  if (length(unique(x))>=length(unique(poigen))){
    barplot(table(poigen), width=0.5, space=c(0.9, rep(1.4, length(unique(poigen))-1)), 
            col="red", add=TRUE, names.arg = "")
  } else {
    barplot(table(poigen), width=0.5, space=c(0.9, rep(1.4, length(unique(poigen))-1)), 
            col="red", add=TRUE, names.arg = c(rep("", length(unique(x))), (length(unique(x)) + 1):length(unique(poigen))))
  }
  legend(18, max(max(table(x)), max(table(poigen))) - 100, 
         legend=c("Data", expression(paste("Poisson Dist., ", lambda, " = ", mu[i]))),
         col=c("grey", "red"), pch= 15, cex = 0.8)
}

dataplot2(df$ofp, lambda = pfitted)
```

It's quite clear that `ofp` doesn't follow a regular Poisson distribution, and some peculiar characteristics of the response variable's distribution are evident in the plot. For the sake of convenience we let the random variable $X$ represent the `ofp` response. We note that the mean of `ofp` is $\lambda = E[X] = `r mui`$ on average, but the variance of the distribution on average is much higher than the mean, with $\text{Var}(X) = `r vari` \ne \lambda$. 

In a Poisson regression model, it's important that the mean of the Poisson output is equal to the variance. Sometimes, the variance is greater than the mean, which is called overdispersion, and we can see this visually in the plot by looking at the spread of the grey data, and how much further left and right of the red true distribution it spreads. This basically confirms that the regular Poisson regression of the data won't fit well, and we need to introduce the modelling of a second parameter, called the dispersion parameter, to properly model the data. Accounting for overdispersion in the response variable can be done by either fitting a negative binomial model or a quasi-poisson model to the data. Lastly, we will also consider a zero-inflated negative binomial model, as there appear to be a disproportionate number of zeros in the response.

### Quasi-Poisson or Negative Binomial?

In regular Poisson regression, a key assumption that's made is that the variance of the response variable is equal to the mean. If the response's variance is larger than its mean, the response is overdispersed, and either Negative Binomial regression or Quasi-Poisson regression should be used. Both quasi poisson and negative binomial models include a second parameter to separately model the relationship between the variance the mean.

In the Quasi-Poisson case, the variance follows a linear relationship with the mean. If $Y$ is our response variable, and $E[Y] = \mu$, then we have $\text{Var}(Y) = \theta \mu$, where $\theta$ is the Quasi-Poisson overdispersion parameter.

In the Negative binomial case, the variance follows a quadratic relationship with the mean. For example, if $E[Y] = \mu$, then we have $\text{Var}(Y) = \mu + \kappa \mu^2$, where $\kappa$ is the Negative Binomial dispersion parameter.

In order to decide which method is best, we have to look at the relationship between the means $\mu_i$ and the squared residuals of the regular poisson fit $(Y_i-\mu_i)^2$ in comparison with the two variance relationships. In order to do this, we first estimate both overdispersion parameters $\theta$ and $\kappa$ using `dispersiontest()` from `library(AER)`, which tests the null hypothesis of equidispersion in Poisson GLMs against the alternative hypothesis that there is overdispersion. The coefficient can be estimated by an auxiliary OLS regression and tested with the corresponding $t$ (or $z$) statistic which is asymptotically distributed as $N(0,1)$ under $H_0$ [see Cameron, A.C. and Trivedi, P.K. (1990)].

The test with parameter `trafo = 1` performs a statistical test on $H_0: \alpha = 0$ against the alternative $H_1: \alpha > 0$ where $\text{Var}(Y) = \theta \mu = (1+\alpha)\mu$ for overdispersion in the Quasi-Poisson case and provides an estimate of $\alpha$.

If we instead set `trafo = 2` performs a statistical test on $H_0: \alpha = 0$ against the alternative $H_1: \alpha > 0$ where $\text{Var}(Y) = \mu + \kappa \mu^2 = \mu + \alpha \mu^2$ for overdispersion in the Negative Binomial case and provides an estimate of $\alpha$:


```{r}
### Dispersion Test from library(AER)
qpdtest <- dispersiontest(pfit, trafo = 1)
nbdtest <- dispersiontest(pfit, trafo = 2)

### Dispersion Parameter Estimates
qpdisp <- 1 + qpdtest$estimate
nbdisp <- nbdtest$estimate

### Dispersion Test p-values
qpdispp <- qpdtest$p.value
nbdispp <- nbdtest$p.value

### Squared Residuals
presids <- (df$ofp - pfitted)^2

### Variance Functions
varqp <- function(mu){
  qpdisp * mu
}

varnb <- function(mu){
  mu + nbdisp * mu^2
}
```

In the Quasi-Poisson case, we estimate the dispersion parameter to be $\theta = `r qpdisp`$ and the relationship of the variance to the mean can be written as $\text{Var}(Y) = (1+`r qpdisp`) \mu$. With respect to the previously outlined test, we reject $H_0$ with associated $p\text{-value}= `r qpdispp`$, which means that there's extremely strong evidence that $\alpha >0$.

In the Negative Binomial case, we take the dispersion parameter to be $\kappa = `r nbdisp`$ and the relationship of the variance to the mean can be written as $\text{Var}(Y) = \mu + `r nbdisp` \mu^2$. With respect to the previously outlined test, we reject $H_0$ with associated $p\text{-value}= `r nbdispp`$, which means that there's extremely strong evidence that $\alpha > 0$.

We now take a look at the relationship between the squared residuals of the regular Poisson regression model and the means:


```{r, echo=FALSE}
meanvec <- Inf
sizes   <- Inf
uniques <- unique(round(pfitted, 1))

for (i in uniques){
  ind <- round(pfitted, 1) == i
  meanvec <- c(meanvec, mean(presids[ind]))
  sizes <- c(sizes, sum(ind))
}

meanvec <- meanvec[-1]
sizes   <- sizes[-1]

### Plot
plot(x = uniques, y = meanvec, ylim = c(0, 130), 
     xlab = expression(paste("Mean ", mu[i])), 
     ylab = expression(paste("Residuals ", (Y[i]-mu[i])^2)),
     main = 'Average Squared Residuals by Fitted Values',
     xlim = c(0, 15), cex = sqrt(sizes*200/(sum(sizes))))
curve(varqp, col = 'red', add = TRUE, lty = 'dashed', lwd = 2)
curve(varnb, col = 'blue', add = TRUE, lty = 'dashed', lwd = 2)
legend(11.5, 130, legend = c("Negative Binomial", "Quasi-Poisson"),
       col=c("blue", "red"), pch= 15, cex = 0.8)
```

The previous plot shows average squared residuals by fitted means. The fitted mean values were rounded to one decimal place and residual values that shared the same means were averaged. The size of the circles corresponds to the proportion (or the weight) of response values representing the same mean value. 

The red dashed line represents the linear relationship that the variance should follow if the model should be fit with a Quasi-Poisson family, and the blue dashed line represents the quadratic relationship that the variance should follow if the model should be fit with a Negative Binomial family. It's quite clear from the plot that a vast majority of the residuals follow the quadratic relationship much better than they do the linear relationship. For this reason, we will stick to the Negative Binomial family when fitting the model.

Using the full Negative Binomial model fit we used in the previous section, we can look at a new distribution plot using the Negative Binomial fitted values and see if the distribution comparison with the data is better:

```{r, echo = FALSE}
nbfitted <- fitted(nbfit)

dataplot3 <- function(x, lambda, kappa){
  poigen <- rnbinom(length(x), mu = lambda, size = (1/kappa))
  barplot(table(x), xlab = "Number of Physician Office Visits in 1987", ylim = c(0, 800),
          ylab = "Response Frequency", xlim = c(0, ifelse(length(unique(poigen))>=length(unique(x)), 
                                                 length(unique(poigen))+2, min(length(unique(x))+2, 24.9))),
          main = "Distribution Comparison of Response")
  if (length(unique(x))>=length(unique(poigen))){
    barplot(table(poigen), width=0.5, space=c(0.9, rep(1.4, length(unique(poigen))-1)), 
            col="red", add=TRUE, names.arg = "")
  } else {
    barplot(table(poigen), width=0.5, space=c(0.9, rep(1.4, length(unique(poigen))-1)), 
            col="red", add=TRUE, names.arg = c(rep("", length(unique(x))), 
                                               (length(unique(x)) + 1):length(unique(poigen))))
  }
  legend(15, max(max(table(x)), max(table(poigen))) - 150, 
         legend=c("Data", "Negative Binomial Dist., ", 
                  expression(paste(" ", mu, " = ", mu[i], ", ", kappa, " = ", 1.01311))),
         col=c("grey", "red", "white"), pch= 15, cex = 0.8)
}

dataplot3(df$ofp, lambda = nbfitted, kappa = nbdisp)
```

It's quite clear that the Negative Binomial family fits the data much better than the ordinary Poisson distribution. This relationship can be seen visually in the above plot.






